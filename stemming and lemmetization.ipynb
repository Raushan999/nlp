{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae758ebd-6f08-4f9e-8a9a-19f315c9a16f",
   "metadata": {},
   "source": [
    "#### Stemming:- using fixed set of rules to bring the word to base form, ex:- ing, able, ed removal\n",
    "#### lemmatiztion:- using knowledge of language to derive the base word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f1b3652f-f848-4ba6-b244-21b2bfb1f8ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e9e86369-8e2c-4807-80ae-747645097c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "55633962-0e74-408d-bd41-619c375b9048",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eat\n",
      "go\n",
      "went\n",
      "work\n",
      "abil\n"
     ]
    }
   ],
   "source": [
    "text  = [\"eating\", \"going\", \"went\", \"worked\", \"ability\"]\n",
    "for et in text:\n",
    "    print(stemmer.stem(et))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbdb933f-6976-45e7-9764-21fc0c32cb79",
   "metadata": {},
   "source": [
    "#### We can see that the nltk stemming is not identifying the language properly, distorted the actual meaning of the word"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61bfdd10-5343-4248-b1cf-d8a0407d352e",
   "metadata": {},
   "source": [
    "### So although the stemmer is dumb but its faster and for simple smaller texts it works"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23cefda7-6853-43fd-ba99-042aca86de79",
   "metadata": {},
   "source": [
    "# Using Spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "aa3738c8-12f7-412a-aa1a-a3a220806b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "725a32e5-b2ef-431e-8e8d-78ec8468f939",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eating  |  eat\n",
      "ate  |  eat\n",
      "agility  |  agility\n",
      "dialing  |  dialing\n",
      "dialed  |  dial\n",
      "went  |  go\n",
      "going  |  go\n"
     ]
    }
   ],
   "source": [
    "text = \"eating ate agility dialing dialed went going\"\n",
    "doc = nlp(text)\n",
    "for item in doc:\n",
    "    print(item, \" | \", item.lemma_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9a23f8c5-a3f9-4706-ac26-aa471a2025c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## We can see that the words have been mapped properly using ligustic knowledge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ec8e69f6-85ee-4986-8f63-5793bc1312a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tok2vec', 'tagger', 'parser', 'attribute_ruler', 'lemmatizer', 'ner']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.pipe_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7185952d-3ef6-45b4-b322-12dd890f57dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using attribute_ruler component, we can acutally modify the way lemmatizer works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7aad74f4-b9b5-4da1-a6ac-a1f193f41993",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bro\n",
      "do\n",
      "not\n",
      "say\n",
      "no\n",
      "to\n",
      "brah\n",
      ",\n",
      "I\n",
      "be\n",
      "exhaust\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"bro don't say no to brah, I am exhausted\")\n",
    "for token in doc:\n",
    "    print(token.lemma_)\n",
    "# we see that the bro and brah are treated differently here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a618d383-6212-40dc-bff8-3973229d3ee6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bro  |  Brother\n",
      "do  |  do\n",
      "n't  |  not\n",
      "say  |  say\n",
      "no  |  no\n",
      "to  |  to\n",
      "brah  |  Brother\n",
      ",  |  ,\n",
      "I  |  I\n",
      "am  |  be\n",
      "exhausted  |  exhaust\n"
     ]
    }
   ],
   "source": [
    "ar = nlp.get_pipe('attribute_ruler')\n",
    "ar.add( [ [{\"TEXT\":\"bro\"}], [{\"TEXT\": \"brah\"}]], {\"LEMMA\":\"Brother\"})\n",
    "doc = nlp(\"bro don't say no to brah, I am exhausted\")\n",
    "\n",
    "for token in doc:\n",
    "    print(token.text, \" | \", token.lemma_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b809c3b7-af86-4ee6-9657-188d7575b8c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we customized our nlp pipeline to treat the lemmatizer as per our need."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9dd5948-dfcc-4495-85cc-5b93320feb6c",
   "metadata": {},
   "source": [
    "# Exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1632352f-ab7f-4aab-910c-f89d8b1f3843",
   "metadata": {},
   "source": [
    "## Exercise1:\n",
    "\n",
    "* Convert these list of words into base form using Stemming and Lemmatization and observe the transformations\n",
    "* Write a short note on the words that have different base words using stemming and Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f3db392d-fbbc-4d7a-8c78-db1272ba162a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#using stemming in nltk\n",
    "lst_words = ['running', 'painting', 'walking', 'dressing', 'likely', 'children', 'whom', 'good', 'ate', 'fishing']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4471cfda-3b98-4e13-ada2-a0238b8fd1fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the necessary libraries again:\n",
    "import nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "953c7711-803a-4176-a381-3889c2dab0c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run\n",
      "paint\n",
      "walk\n",
      "dress\n",
      "like\n",
      "children\n",
      "whom\n",
      "good\n",
      "ate\n",
      "fish\n"
     ]
    }
   ],
   "source": [
    "for word in lst_words:\n",
    "    print(stemmer.stem(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90941370-0437-49ec-9fc8-7516e6aa73fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8908b27b-cae3-4dab-a493-722fe4ab4aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the libraries again:\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8c7f9763-d200-420a-a9fa-c92debd8bc28",
   "metadata": {},
   "outputs": [],
   "source": [
    "#using lemmatization in spacy\n",
    "doc = nlp(\"running painting walking dressing likely children who good ate fishing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4b7f6c94-0b84-45b6-8d3d-89603b095d06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running  |  run\n",
      "painting  |  paint\n",
      "walking  |  walk\n",
      "dressing  |  dress\n",
      "likely  |  likely\n",
      "children  |  child\n",
      "who  |  who\n",
      "good  |  good\n",
      "ate  |  eat\n",
      "fishing  |  fishing\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(token, \" | \", token.lemma_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "2900af10-977c-4c5e-94f8-39a1be394801",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Observing the difference in the two techniques:\n",
    "org =  ['running', 'painting', 'walking', 'dressing', 'likely', 'children', 'whom', 'good', 'ate', 'fishing']\n",
    "stem = []\n",
    "lemmet = []\n",
    "for token in org:\n",
    "    stem.append(stemmer.stem(token))\n",
    "for token in doc:\n",
    "    lemmet.append(token.lemma_)\n",
    "# ans = pd.Dataframe(org, stem, lemmet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "1941170e-eae4-45eb-be1c-a552ee9f3d69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'> <class 'list'> <class 'list'>\n"
     ]
    }
   ],
   "source": [
    "print(type(org), type(stem), type(lemmet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "fb123562-e40e-480c-9312-514906766a2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>orginal</th>\n",
       "      <th>stemmed form</th>\n",
       "      <th>lemmetized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>running</td>\n",
       "      <td>run</td>\n",
       "      <td>run</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>painting</td>\n",
       "      <td>paint</td>\n",
       "      <td>paint</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>walking</td>\n",
       "      <td>walk</td>\n",
       "      <td>walk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dressing</td>\n",
       "      <td>dress</td>\n",
       "      <td>dress</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>likely</td>\n",
       "      <td>like</td>\n",
       "      <td>likely</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>children</td>\n",
       "      <td>children</td>\n",
       "      <td>child</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>whom</td>\n",
       "      <td>whom</td>\n",
       "      <td>who</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>good</td>\n",
       "      <td>good</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ate</td>\n",
       "      <td>ate</td>\n",
       "      <td>eat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>fishing</td>\n",
       "      <td>fish</td>\n",
       "      <td>fishing</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    orginal stemmed form lemmetized\n",
       "0   running          run        run\n",
       "1  painting        paint      paint\n",
       "2   walking         walk       walk\n",
       "3  dressing        dress      dress\n",
       "4    likely         like     likely\n",
       "5  children     children      child\n",
       "6      whom         whom        who\n",
       "7      good         good       good\n",
       "8       ate          ate        eat\n",
       "9   fishing         fish    fishing"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# converting all the list elements to dataframe/ tabular form to see the difference.\n",
    "df  = pd.DataFrame(list(zip(org,stem,lemmet)), columns = ['orginal', 'stemmed form', 'lemmetized'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4af2b911-4e7a-4f25-b9fe-7cb171bdda94",
   "metadata": {},
   "source": [
    "## Exercise2:\n",
    "\n",
    "convert the given text into it's base form using both stemming and lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "003cf3b0-9b95-4d2b-ad2e-8689ebb6d809",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"Latha is very multi talented girl. She is good at many skills like dancing, running, singing, playing. She also likes eating Pav Bhagi. she has a habit of fishing and swimming too. Besides all this, she is a wonderful at cooking too.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "9c9fe6da-7b9e-4543-8b7c-6d49337834fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#using stemming in nltk\n",
    "#step1: Word tokenizing\n",
    "#step2: getting the base form for each token using stemmer\n",
    "#step3: joining all words in a list into string using 'join()'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "bdebabd5-5db1-4c7c-a52a-331d6d5952d6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# converting the paragraph to tokens:\n",
    "org_word_token = nltk.word_tokenize(text)\n",
    "stem_word = []\n",
    "lemmet_word = []\n",
    "for token in org_word_token:\n",
    "    stem_word.append(stemmer.stem(token))\n",
    "doc = nlp(text)\n",
    "for sent in doc.sents:\n",
    "    for token in sent:\n",
    "        lemmet_word.append(token.lemma_)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "8ed5784f-230d-4603-9985-3681980431e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'latha is veri multi talent girl . she is good at mani skill like danc , run , sing , play . she also like eat pav bhagi . she ha a habit of fish and swim too . besid all thi , she is a wonder at cook too .'"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(stem_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "0f292e8f-4187-429c-80fe-d12e228b152b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original</th>\n",
       "      <th>stemmed</th>\n",
       "      <th>lemmetized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Latha</td>\n",
       "      <td>latha</td>\n",
       "      <td>Latha</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>is</td>\n",
       "      <td>is</td>\n",
       "      <td>be</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>very</td>\n",
       "      <td>veri</td>\n",
       "      <td>very</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>multi</td>\n",
       "      <td>multi</td>\n",
       "      <td>multi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>talented</td>\n",
       "      <td>talent</td>\n",
       "      <td>talented</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>girl</td>\n",
       "      <td>girl</td>\n",
       "      <td>girl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>She</td>\n",
       "      <td>she</td>\n",
       "      <td>she</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>is</td>\n",
       "      <td>is</td>\n",
       "      <td>be</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>good</td>\n",
       "      <td>good</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>at</td>\n",
       "      <td>at</td>\n",
       "      <td>at</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>many</td>\n",
       "      <td>mani</td>\n",
       "      <td>many</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>skills</td>\n",
       "      <td>skill</td>\n",
       "      <td>skill</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>like</td>\n",
       "      <td>like</td>\n",
       "      <td>like</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>dancing</td>\n",
       "      <td>danc</td>\n",
       "      <td>dancing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>running</td>\n",
       "      <td>run</td>\n",
       "      <td>running</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>singing</td>\n",
       "      <td>sing</td>\n",
       "      <td>singing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>playing</td>\n",
       "      <td>play</td>\n",
       "      <td>play</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>She</td>\n",
       "      <td>she</td>\n",
       "      <td>she</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>also</td>\n",
       "      <td>also</td>\n",
       "      <td>also</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>likes</td>\n",
       "      <td>like</td>\n",
       "      <td>like</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>eating</td>\n",
       "      <td>eat</td>\n",
       "      <td>eat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Pav</td>\n",
       "      <td>pav</td>\n",
       "      <td>Pav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Bhagi</td>\n",
       "      <td>bhagi</td>\n",
       "      <td>Bhagi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>she</td>\n",
       "      <td>she</td>\n",
       "      <td>she</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>has</td>\n",
       "      <td>ha</td>\n",
       "      <td>have</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>habit</td>\n",
       "      <td>habit</td>\n",
       "      <td>habit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>of</td>\n",
       "      <td>of</td>\n",
       "      <td>of</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>fishing</td>\n",
       "      <td>fish</td>\n",
       "      <td>fishing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>and</td>\n",
       "      <td>and</td>\n",
       "      <td>and</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>swimming</td>\n",
       "      <td>swim</td>\n",
       "      <td>swim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>too</td>\n",
       "      <td>too</td>\n",
       "      <td>too</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Besides</td>\n",
       "      <td>besid</td>\n",
       "      <td>besides</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>all</td>\n",
       "      <td>all</td>\n",
       "      <td>all</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>this</td>\n",
       "      <td>thi</td>\n",
       "      <td>this</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>she</td>\n",
       "      <td>she</td>\n",
       "      <td>she</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>is</td>\n",
       "      <td>is</td>\n",
       "      <td>be</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>wonderful</td>\n",
       "      <td>wonder</td>\n",
       "      <td>wonderful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>at</td>\n",
       "      <td>at</td>\n",
       "      <td>at</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>cooking</td>\n",
       "      <td>cook</td>\n",
       "      <td>cook</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>too</td>\n",
       "      <td>too</td>\n",
       "      <td>too</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     original stemmed lemmetized\n",
       "0       Latha   latha      Latha\n",
       "1          is      is         be\n",
       "2        very    veri       very\n",
       "3       multi   multi      multi\n",
       "4    talented  talent   talented\n",
       "5        girl    girl       girl\n",
       "6           .       .          .\n",
       "7         She     she        she\n",
       "8          is      is         be\n",
       "9        good    good       good\n",
       "10         at      at         at\n",
       "11       many    mani       many\n",
       "12     skills   skill      skill\n",
       "13       like    like       like\n",
       "14    dancing    danc    dancing\n",
       "15          ,       ,          ,\n",
       "16    running     run    running\n",
       "17          ,       ,          ,\n",
       "18    singing    sing    singing\n",
       "19          ,       ,          ,\n",
       "20    playing    play       play\n",
       "21          .       .          .\n",
       "22        She     she        she\n",
       "23       also    also       also\n",
       "24      likes    like       like\n",
       "25     eating     eat        eat\n",
       "26        Pav     pav        Pav\n",
       "27      Bhagi   bhagi      Bhagi\n",
       "28          .       .          .\n",
       "29        she     she        she\n",
       "30        has      ha       have\n",
       "31          a       a          a\n",
       "32      habit   habit      habit\n",
       "33         of      of         of\n",
       "34    fishing    fish    fishing\n",
       "35        and     and        and\n",
       "36   swimming    swim       swim\n",
       "37        too     too        too\n",
       "38          .       .          .\n",
       "39    Besides   besid    besides\n",
       "40        all     all        all\n",
       "41       this     thi       this\n",
       "42          ,       ,          ,\n",
       "43        she     she        she\n",
       "44         is      is         be\n",
       "45          a       a          a\n",
       "46  wonderful  wonder  wonderful\n",
       "47         at      at         at\n",
       "48    cooking    cook       cook\n",
       "49        too     too        too\n",
       "50          .       .          ."
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(list(zip(org_word_token, stem_word, lemmet_word)), columns= ['original', 'stemmed', 'lemmetized'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fffa610-13ef-466a-ad7e-c6b51cb6461f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
